{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cours 1 \n",
    "\n",
    "\n",
    "### L'IA  \n",
    "\n",
    "L'ensemble de théories et des techniques randant les machines capables de simuler l'intelligence. Né en 1956.  \n",
    "- Cognition-Based: Reproduire la logique de l'homme\n",
    "- Data-Driven: Reproduire le comportement de l'homme  \n",
    "\n",
    "Ref : \"Machine Learning\" Andrew NJ Coursera and \"Deep Learning\"\n",
    "\n",
    "Dataset -> ML Model -> h(x)  \n",
    "New input -> h(x) -> predict output\n",
    "\n",
    "<font color='red'>Terminology</font>  \n",
    "m observations [n feature, 1 label] : [x<sup>(i)</sup>, y<sup>(i)</sup>]  \n",
    "n features\n",
    "\n",
    "**<font color='red'>Linear Model</font>**  \n",
    "h(x) = w<sub>0</sub> +  w<sub>1</sub>x  \n",
    "Cost function : J<sub>(w<sub>0</sub>, w<sub>1</sub>)</sub> = $\\sum_{i=0}^{nb}$ ^y<sup>(i)</sup> - y<sup>(i)</sup>  \n",
    "Square Error Cost function : J<sub>(w<sub>0</sub>, w<sub>1</sub>)</sub> = $\\frac{1}{2m}$ $\\sum_{i=0}^{nb}$ (h<sub>w</sub>(x<sup>(i)</sup>) - y<sup>(i)</sup>)\n",
    "\n",
    "**Gradient Descent**:  \n",
    "w = w - $\\alpha$ $\\frac{\\delta J}{\\delta w}$   \n",
    "Repeat until convergence.  \n",
    "w<sub>j</sub> = w<sub>j</sub> - $\\alpha$ ($\\frac{1}{m}$ $\\sum_{i=0}^{nb}$ (h<sub>w</sub>(x<sup>(i)</sup>) - y<sup>(i)</sup>) x<sub>j</sub><sup>(i)</sup>  \n",
    "Update w<sub>i</sub> simultanément\n",
    "\n",
    "\n",
    "<font color='red'>Feature scaling</font>  \n",
    "x<sub>i</sub> = $\\frac{xi}{\\max (xi)}$  \n",
    "Mean normalize  \n",
    "x = $\\frac{x - mean}{S}$\n",
    "\n",
    "\n",
    "**<font color='red'>Polynomial Reg</font>**:   \n",
    "h<sub>w</sub>(x) = w<sub>0</sub> + w<sub>1</sub>x<sub>1</sub> + w<sub>2</sub>x<sub>2</sub> + ... + w<sub>n</sub>x<sub>n</sub>  \n",
    "^y =h(x) = w<sup>T</sup>.x\n",
    "\n",
    "<font color='red'>Normal Equation</font>  \n",
    "w = (X<sup>T</sup>.X)<sup>-1</sup>.X<sup>T</sup>.y\n",
    "\n",
    "w = (n + 1) * 1  (dépend de la taille de la matrice n + 1 lignes et 1 col)  \n",
    "x = (n + 1) * 1  \n",
    "y = m * 1  \n",
    "\n",
    "J<sub>w</sub> = $\\frac{1}{2m}$ $\\sum_{i=0}^{nb}$ (h<sub>w</sub>(x<sup>(i)</sup>) - y<sup>(i)</sup>) x<sub>j</sub><sup>(i)</sup> )<sup>2</sup>  \n",
    "$\\frac{\\delta J}{\\delta W}$ = 0 = $\\frac{1}{m}$ $\\sum_{i=0}^{nb}$ (h<sub>w</sub>(x<sup>(i)</sup>) - y<sup>(i)</sup>) x<sub>k</sub><sup>(i)</sup>  \n",
    "h<sub>w</sub>(x<sup>(i)</sup>) - y<sup>(i)</sup> = (X<sub>w</sub> - y)  \n",
    "X<sup>T</sup>.(Xw - y) = 0  <=>  \n",
    "X<sup>T</sup>.Xw - X<sup>T</sup>.y = 0 <=>  \n",
    "(X<sup>T</sup>.X)w = X<sup>T</sup>.y <=>  \n",
    "(X<sup>T</sup>.X)<sup>-1</sup>.(X<sup>T</sup>.X)w = (X<sup>T</sup>.X)<sup>-1</sup>.X<sup>T</sup>.y <=>  \n",
    "w = (X<sup>T</sup>.X)<sup>-1</sup>.X<sup>T</sup>.y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
